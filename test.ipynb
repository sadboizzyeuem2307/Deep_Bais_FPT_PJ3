{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = 64, 64\n",
    "num_classes = 165\n",
    "images = []\n",
    "labels = []\n",
    "class_label_mapping = {}\n",
    "class_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'D:\\Project3\\tai\\EarVN1.0 dataset\\Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((image_width, image_height))\n",
    "    img = np.array(img)\n",
    "    img = img / 255.0 \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in os.listdir(dataset_path):\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if not os.path.isdir(class_folder):\n",
    "        continue\n",
    "\n",
    "    # Create a unique integer label for each class\n",
    "    class_label_mapping[class_name] = class_count\n",
    "    class_count += 1\n",
    "\n",
    "    for image_name in os.listdir(class_folder):\n",
    "        image_path = os.path.join(class_folder, image_name)\n",
    "        img = preprocess_image(image_path)\n",
    "        images.append(img)\n",
    "        labels.append(class_label_mapping[class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "labels = to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, temp_images, train_labels, temp_labels = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(temp_images, temp_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               1179904   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 165)               42405     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,315,557\n",
      "Trainable params: 1,315,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 5.1004 - accuracy: 0.0087 - val_loss: 5.0891 - val_accuracy: 0.0084\n",
      "Epoch 2/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 5.0383 - accuracy: 0.0138 - val_loss: 4.9695 - val_accuracy: 0.0134\n",
      "Epoch 3/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.9970 - accuracy: 0.0151 - val_loss: 4.9404 - val_accuracy: 0.0155\n",
      "Epoch 4/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.9738 - accuracy: 0.0173 - val_loss: 4.8980 - val_accuracy: 0.0202\n",
      "Epoch 5/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.9478 - accuracy: 0.0166 - val_loss: 4.8764 - val_accuracy: 0.0197\n",
      "Epoch 6/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.9236 - accuracy: 0.0187 - val_loss: 4.8580 - val_accuracy: 0.0235\n",
      "Epoch 7/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.8926 - accuracy: 0.0201 - val_loss: 4.7795 - val_accuracy: 0.0293\n",
      "Epoch 8/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.8672 - accuracy: 0.0234 - val_loss: 4.7452 - val_accuracy: 0.0336\n",
      "Epoch 9/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.8425 - accuracy: 0.0240 - val_loss: 4.7262 - val_accuracy: 0.0397\n",
      "Epoch 10/1000\n",
      "622/622 [==============================] - 16s 25ms/step - loss: 4.8118 - accuracy: 0.0270 - val_loss: 4.6640 - val_accuracy: 0.0422\n",
      "Epoch 11/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.7904 - accuracy: 0.0311 - val_loss: 4.6364 - val_accuracy: 0.0415\n",
      "Epoch 12/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.7582 - accuracy: 0.0327 - val_loss: 4.6029 - val_accuracy: 0.0436\n",
      "Epoch 13/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.7376 - accuracy: 0.0337 - val_loss: 4.5741 - val_accuracy: 0.0497\n",
      "Epoch 14/1000\n",
      "622/622 [==============================] - 16s 26ms/step - loss: 4.7224 - accuracy: 0.0335 - val_loss: 4.5570 - val_accuracy: 0.0540\n",
      "Epoch 15/1000\n",
      "622/622 [==============================] - 16s 26ms/step - loss: 4.7031 - accuracy: 0.0376 - val_loss: 4.5329 - val_accuracy: 0.0523\n",
      "Epoch 16/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.6927 - accuracy: 0.0366 - val_loss: 4.5092 - val_accuracy: 0.0617\n",
      "Epoch 17/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.6707 - accuracy: 0.0391 - val_loss: 4.4882 - val_accuracy: 0.0634\n",
      "Epoch 18/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.6605 - accuracy: 0.0401 - val_loss: 4.4628 - val_accuracy: 0.0671\n",
      "Epoch 19/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.6468 - accuracy: 0.0417 - val_loss: 4.4418 - val_accuracy: 0.0727\n",
      "Epoch 20/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.6390 - accuracy: 0.0443 - val_loss: 4.4270 - val_accuracy: 0.0676\n",
      "Epoch 21/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.6213 - accuracy: 0.0468 - val_loss: 4.4279 - val_accuracy: 0.0695\n",
      "Epoch 22/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.6028 - accuracy: 0.0462 - val_loss: 4.4010 - val_accuracy: 0.0730\n",
      "Epoch 23/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5916 - accuracy: 0.0464 - val_loss: 4.4045 - val_accuracy: 0.0727\n",
      "Epoch 24/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5797 - accuracy: 0.0485 - val_loss: 4.3683 - val_accuracy: 0.0805\n",
      "Epoch 25/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5816 - accuracy: 0.0486 - val_loss: 4.3382 - val_accuracy: 0.0805\n",
      "Epoch 26/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5636 - accuracy: 0.0508 - val_loss: 4.3396 - val_accuracy: 0.0746\n",
      "Epoch 27/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5621 - accuracy: 0.0527 - val_loss: 4.3410 - val_accuracy: 0.0760\n",
      "Epoch 28/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.5450 - accuracy: 0.0502 - val_loss: 4.3209 - val_accuracy: 0.0786\n",
      "Epoch 29/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5364 - accuracy: 0.0547 - val_loss: 4.3123 - val_accuracy: 0.0777\n",
      "Epoch 30/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.5327 - accuracy: 0.0523 - val_loss: 4.3105 - val_accuracy: 0.0889\n",
      "Epoch 31/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5256 - accuracy: 0.0530 - val_loss: 4.3194 - val_accuracy: 0.0847\n",
      "Epoch 32/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5064 - accuracy: 0.0597 - val_loss: 4.2913 - val_accuracy: 0.0840\n",
      "Epoch 33/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5056 - accuracy: 0.0570 - val_loss: 4.2949 - val_accuracy: 0.0833\n",
      "Epoch 34/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.5035 - accuracy: 0.0560 - val_loss: 4.2434 - val_accuracy: 0.0882\n",
      "Epoch 35/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.4910 - accuracy: 0.0573 - val_loss: 4.2585 - val_accuracy: 0.0936\n",
      "Epoch 36/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4861 - accuracy: 0.0585 - val_loss: 4.2456 - val_accuracy: 0.0906\n",
      "Epoch 37/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4855 - accuracy: 0.0589 - val_loss: 4.2577 - val_accuracy: 0.0917\n",
      "Epoch 38/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4720 - accuracy: 0.0575 - val_loss: 4.2614 - val_accuracy: 0.0983\n",
      "Epoch 39/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4607 - accuracy: 0.0619 - val_loss: 4.2309 - val_accuracy: 0.0924\n",
      "Epoch 40/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4646 - accuracy: 0.0600 - val_loss: 4.2541 - val_accuracy: 0.0917\n",
      "Epoch 41/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4512 - accuracy: 0.0631 - val_loss: 4.2054 - val_accuracy: 0.0960\n",
      "Epoch 42/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.4563 - accuracy: 0.0609 - val_loss: 4.2108 - val_accuracy: 0.0967\n",
      "Epoch 43/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4427 - accuracy: 0.0625 - val_loss: 4.1835 - val_accuracy: 0.1061\n",
      "Epoch 44/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4339 - accuracy: 0.0653 - val_loss: 4.1651 - val_accuracy: 0.1068\n",
      "Epoch 45/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.4424 - accuracy: 0.0627 - val_loss: 4.1786 - val_accuracy: 0.1070\n",
      "Epoch 46/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.4274 - accuracy: 0.0647 - val_loss: 4.1727 - val_accuracy: 0.0995\n",
      "Epoch 47/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.4159 - accuracy: 0.0644 - val_loss: 4.2217 - val_accuracy: 0.0971\n",
      "Epoch 48/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4159 - accuracy: 0.0675 - val_loss: 4.2228 - val_accuracy: 0.0948\n",
      "Epoch 49/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4119 - accuracy: 0.0673 - val_loss: 4.1679 - val_accuracy: 0.1021\n",
      "Epoch 50/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.4131 - accuracy: 0.0672 - val_loss: 4.1533 - val_accuracy: 0.1089\n",
      "Epoch 51/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.4108 - accuracy: 0.0664 - val_loss: 4.1489 - val_accuracy: 0.1100\n",
      "Epoch 52/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.4031 - accuracy: 0.0671 - val_loss: 4.1190 - val_accuracy: 0.1084\n",
      "Epoch 53/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.3957 - accuracy: 0.0691 - val_loss: 4.1103 - val_accuracy: 0.1152\n",
      "Epoch 54/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.3912 - accuracy: 0.0693 - val_loss: 4.1341 - val_accuracy: 0.1131\n",
      "Epoch 55/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.3873 - accuracy: 0.0692 - val_loss: 4.1291 - val_accuracy: 0.1152\n",
      "Epoch 56/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3774 - accuracy: 0.0730 - val_loss: 4.1904 - val_accuracy: 0.1056\n",
      "Epoch 57/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3856 - accuracy: 0.0706 - val_loss: 4.1493 - val_accuracy: 0.1110\n",
      "Epoch 58/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3837 - accuracy: 0.0677 - val_loss: 4.1692 - val_accuracy: 0.1096\n",
      "Epoch 59/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.3664 - accuracy: 0.0726 - val_loss: 4.1034 - val_accuracy: 0.1126\n",
      "Epoch 60/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.3643 - accuracy: 0.0729 - val_loss: 4.0911 - val_accuracy: 0.1154\n",
      "Epoch 61/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.3647 - accuracy: 0.0732 - val_loss: 4.1446 - val_accuracy: 0.1161\n",
      "Epoch 62/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3510 - accuracy: 0.0730 - val_loss: 4.1458 - val_accuracy: 0.1150\n",
      "Epoch 63/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3696 - accuracy: 0.0719 - val_loss: 4.1257 - val_accuracy: 0.1183\n",
      "Epoch 64/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3484 - accuracy: 0.0733 - val_loss: 4.2009 - val_accuracy: 0.1030\n",
      "Epoch 65/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3665 - accuracy: 0.0703 - val_loss: 4.1354 - val_accuracy: 0.1133\n",
      "Epoch 66/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3524 - accuracy: 0.0746 - val_loss: 4.1069 - val_accuracy: 0.1136\n",
      "Epoch 67/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3498 - accuracy: 0.0726 - val_loss: 4.0793 - val_accuracy: 0.1218\n",
      "Epoch 68/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3482 - accuracy: 0.0735 - val_loss: 4.0936 - val_accuracy: 0.1239\n",
      "Epoch 69/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3409 - accuracy: 0.0749 - val_loss: 4.0550 - val_accuracy: 0.1298\n",
      "Epoch 70/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.3374 - accuracy: 0.0756 - val_loss: 4.0602 - val_accuracy: 0.1293\n",
      "Epoch 71/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.3327 - accuracy: 0.0756 - val_loss: 4.0903 - val_accuracy: 0.1265\n",
      "Epoch 72/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3322 - accuracy: 0.0767 - val_loss: 4.0512 - val_accuracy: 0.1225\n",
      "Epoch 73/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3321 - accuracy: 0.0746 - val_loss: 4.0674 - val_accuracy: 0.1211\n",
      "Epoch 74/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3250 - accuracy: 0.0812 - val_loss: 4.0527 - val_accuracy: 0.1244\n",
      "Epoch 75/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.3212 - accuracy: 0.0773 - val_loss: 4.0239 - val_accuracy: 0.1227\n",
      "Epoch 76/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.3123 - accuracy: 0.0783 - val_loss: 4.0775 - val_accuracy: 0.1197\n",
      "Epoch 77/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.3178 - accuracy: 0.0789 - val_loss: 4.0427 - val_accuracy: 0.1251\n",
      "Epoch 78/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.3215 - accuracy: 0.0750 - val_loss: 4.0802 - val_accuracy: 0.1255\n",
      "Epoch 79/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3102 - accuracy: 0.0758 - val_loss: 4.0950 - val_accuracy: 0.1208\n",
      "Epoch 80/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3148 - accuracy: 0.0816 - val_loss: 4.0657 - val_accuracy: 0.1220\n",
      "Epoch 81/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3092 - accuracy: 0.0802 - val_loss: 4.0441 - val_accuracy: 0.1251\n",
      "Epoch 82/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.3151 - accuracy: 0.0801 - val_loss: 4.0914 - val_accuracy: 0.1218\n",
      "Epoch 83/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.3033 - accuracy: 0.0791 - val_loss: 4.0277 - val_accuracy: 0.1321\n",
      "Epoch 84/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2862 - accuracy: 0.0840 - val_loss: 4.1040 - val_accuracy: 0.1168\n",
      "Epoch 85/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.3034 - accuracy: 0.0795 - val_loss: 4.0774 - val_accuracy: 0.1298\n",
      "Epoch 86/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.3097 - accuracy: 0.0784 - val_loss: 4.0525 - val_accuracy: 0.1337\n",
      "Epoch 87/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.3018 - accuracy: 0.0822 - val_loss: 4.0574 - val_accuracy: 0.1262\n",
      "Epoch 88/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2917 - accuracy: 0.0837 - val_loss: 4.0944 - val_accuracy: 0.1208\n",
      "Epoch 89/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2945 - accuracy: 0.0808 - val_loss: 4.0844 - val_accuracy: 0.1255\n",
      "Epoch 90/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2774 - accuracy: 0.0840 - val_loss: 4.0001 - val_accuracy: 0.1373\n",
      "Epoch 91/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2916 - accuracy: 0.0843 - val_loss: 4.0199 - val_accuracy: 0.1305\n",
      "Epoch 92/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2800 - accuracy: 0.0840 - val_loss: 3.9978 - val_accuracy: 0.1427\n",
      "Epoch 93/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2845 - accuracy: 0.0825 - val_loss: 4.0131 - val_accuracy: 0.1326\n",
      "Epoch 94/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2825 - accuracy: 0.0828 - val_loss: 4.0029 - val_accuracy: 0.1274\n",
      "Epoch 95/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2766 - accuracy: 0.0830 - val_loss: 4.0523 - val_accuracy: 0.1328\n",
      "Epoch 96/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2607 - accuracy: 0.0859 - val_loss: 4.0104 - val_accuracy: 0.1344\n",
      "Epoch 97/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2735 - accuracy: 0.0855 - val_loss: 4.0071 - val_accuracy: 0.1370\n",
      "Epoch 98/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2612 - accuracy: 0.0833 - val_loss: 4.0672 - val_accuracy: 0.1248\n",
      "Epoch 99/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2646 - accuracy: 0.0858 - val_loss: 3.9764 - val_accuracy: 0.1380\n",
      "Epoch 100/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2668 - accuracy: 0.0823 - val_loss: 4.0137 - val_accuracy: 0.1333\n",
      "Epoch 101/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2783 - accuracy: 0.0820 - val_loss: 3.9901 - val_accuracy: 0.1394\n",
      "Epoch 102/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2676 - accuracy: 0.0842 - val_loss: 3.9980 - val_accuracy: 0.1340\n",
      "Epoch 103/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2559 - accuracy: 0.0838 - val_loss: 4.0159 - val_accuracy: 0.1288\n",
      "Epoch 104/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2618 - accuracy: 0.0866 - val_loss: 4.0207 - val_accuracy: 0.1290\n",
      "Epoch 105/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2517 - accuracy: 0.0867 - val_loss: 4.0253 - val_accuracy: 0.1321\n",
      "Epoch 106/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2615 - accuracy: 0.0865 - val_loss: 4.0499 - val_accuracy: 0.1269\n",
      "Epoch 107/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2511 - accuracy: 0.0856 - val_loss: 3.9987 - val_accuracy: 0.1349\n",
      "Epoch 108/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2486 - accuracy: 0.0856 - val_loss: 3.9694 - val_accuracy: 0.1436\n",
      "Epoch 109/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2511 - accuracy: 0.0844 - val_loss: 3.9924 - val_accuracy: 0.1415\n",
      "Epoch 110/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2675 - accuracy: 0.0847 - val_loss: 3.9893 - val_accuracy: 0.1373\n",
      "Epoch 111/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2504 - accuracy: 0.0861 - val_loss: 4.0214 - val_accuracy: 0.1347\n",
      "Epoch 112/1000\n",
      "622/622 [==============================] - 16s 25ms/step - loss: 4.2624 - accuracy: 0.0839 - val_loss: 3.9787 - val_accuracy: 0.1272\n",
      "Epoch 113/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2518 - accuracy: 0.0887 - val_loss: 3.9716 - val_accuracy: 0.1314\n",
      "Epoch 114/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2424 - accuracy: 0.0898 - val_loss: 3.9999 - val_accuracy: 0.1290\n",
      "Epoch 115/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2455 - accuracy: 0.0875 - val_loss: 3.9522 - val_accuracy: 0.1356\n",
      "Epoch 116/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2387 - accuracy: 0.0878 - val_loss: 3.9457 - val_accuracy: 0.1427\n",
      "Epoch 117/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2376 - accuracy: 0.0864 - val_loss: 3.9677 - val_accuracy: 0.1422\n",
      "Epoch 118/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2447 - accuracy: 0.0879 - val_loss: 3.9722 - val_accuracy: 0.1312\n",
      "Epoch 119/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2450 - accuracy: 0.0862 - val_loss: 4.0168 - val_accuracy: 0.1267\n",
      "Epoch 120/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2264 - accuracy: 0.0882 - val_loss: 3.9859 - val_accuracy: 0.1387\n",
      "Epoch 121/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2309 - accuracy: 0.0921 - val_loss: 4.0532 - val_accuracy: 0.1269\n",
      "Epoch 122/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2334 - accuracy: 0.0880 - val_loss: 4.0177 - val_accuracy: 0.1326\n",
      "Epoch 123/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2236 - accuracy: 0.0873 - val_loss: 3.9988 - val_accuracy: 0.1251\n",
      "Epoch 124/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2297 - accuracy: 0.0877 - val_loss: 3.9870 - val_accuracy: 0.1380\n",
      "Epoch 125/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2297 - accuracy: 0.0860 - val_loss: 3.9611 - val_accuracy: 0.1337\n",
      "Epoch 126/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2329 - accuracy: 0.0870 - val_loss: 4.0133 - val_accuracy: 0.1253\n",
      "Epoch 127/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2297 - accuracy: 0.0868 - val_loss: 3.9800 - val_accuracy: 0.1382\n",
      "Epoch 128/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.2217 - accuracy: 0.0893 - val_loss: 4.0258 - val_accuracy: 0.1288\n",
      "Epoch 129/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.2177 - accuracy: 0.0924 - val_loss: 3.9902 - val_accuracy: 0.1319\n",
      "Epoch 130/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2360 - accuracy: 0.0886 - val_loss: 3.9685 - val_accuracy: 0.1429\n",
      "Epoch 131/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2173 - accuracy: 0.0894 - val_loss: 4.0403 - val_accuracy: 0.1274\n",
      "Epoch 132/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2118 - accuracy: 0.0910 - val_loss: 3.9418 - val_accuracy: 0.1375\n",
      "Epoch 133/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2038 - accuracy: 0.0910 - val_loss: 3.9836 - val_accuracy: 0.1380\n",
      "Epoch 134/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2108 - accuracy: 0.0912 - val_loss: 3.9447 - val_accuracy: 0.1445\n",
      "Epoch 135/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2269 - accuracy: 0.0899 - val_loss: 3.9425 - val_accuracy: 0.1455\n",
      "Epoch 136/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2116 - accuracy: 0.0896 - val_loss: 3.9788 - val_accuracy: 0.1417\n",
      "Epoch 137/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2087 - accuracy: 0.0918 - val_loss: 3.9844 - val_accuracy: 0.1309\n",
      "Epoch 138/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2249 - accuracy: 0.0911 - val_loss: 3.9444 - val_accuracy: 0.1398\n",
      "Epoch 139/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2075 - accuracy: 0.0902 - val_loss: 3.9628 - val_accuracy: 0.1471\n",
      "Epoch 140/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2086 - accuracy: 0.0943 - val_loss: 3.9392 - val_accuracy: 0.1351\n",
      "Epoch 141/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1943 - accuracy: 0.0912 - val_loss: 3.9265 - val_accuracy: 0.1431\n",
      "Epoch 142/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.2129 - accuracy: 0.0938 - val_loss: 3.9058 - val_accuracy: 0.1499\n",
      "Epoch 143/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.1984 - accuracy: 0.0959 - val_loss: 3.9402 - val_accuracy: 0.1441\n",
      "Epoch 144/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2011 - accuracy: 0.0948 - val_loss: 3.9093 - val_accuracy: 0.1539\n",
      "Epoch 145/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1978 - accuracy: 0.0924 - val_loss: 3.9489 - val_accuracy: 0.1483\n",
      "Epoch 146/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.2099 - accuracy: 0.0906 - val_loss: 3.9298 - val_accuracy: 0.1485\n",
      "Epoch 147/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.2058 - accuracy: 0.0949 - val_loss: 3.9400 - val_accuracy: 0.1429\n",
      "Epoch 148/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.2001 - accuracy: 0.0911 - val_loss: 3.9130 - val_accuracy: 0.1534\n",
      "Epoch 149/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1941 - accuracy: 0.0938 - val_loss: 3.9552 - val_accuracy: 0.1511\n",
      "Epoch 150/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1911 - accuracy: 0.0922 - val_loss: 3.9636 - val_accuracy: 0.1441\n",
      "Epoch 151/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1976 - accuracy: 0.0934 - val_loss: 3.9243 - val_accuracy: 0.1513\n",
      "Epoch 152/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1922 - accuracy: 0.0921 - val_loss: 3.9296 - val_accuracy: 0.1429\n",
      "Epoch 153/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1829 - accuracy: 0.0957 - val_loss: 3.9393 - val_accuracy: 0.1441\n",
      "Epoch 154/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1884 - accuracy: 0.0947 - val_loss: 4.0345 - val_accuracy: 0.1321\n",
      "Epoch 155/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1999 - accuracy: 0.0901 - val_loss: 3.9045 - val_accuracy: 0.1450\n",
      "Epoch 156/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1982 - accuracy: 0.0946 - val_loss: 3.9491 - val_accuracy: 0.1389\n",
      "Epoch 157/1000\n",
      "622/622 [==============================] - 14s 22ms/step - loss: 4.1946 - accuracy: 0.0923 - val_loss: 3.9137 - val_accuracy: 0.1488\n",
      "Epoch 158/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1818 - accuracy: 0.0957 - val_loss: 3.9325 - val_accuracy: 0.1455\n",
      "Epoch 159/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1788 - accuracy: 0.0944 - val_loss: 3.9272 - val_accuracy: 0.1450\n",
      "Epoch 160/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1947 - accuracy: 0.0940 - val_loss: 3.9235 - val_accuracy: 0.1450\n",
      "Epoch 161/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1858 - accuracy: 0.0972 - val_loss: 3.9288 - val_accuracy: 0.1434\n",
      "Epoch 162/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1881 - accuracy: 0.0970 - val_loss: 3.9102 - val_accuracy: 0.1546\n",
      "Epoch 163/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1978 - accuracy: 0.0920 - val_loss: 3.9276 - val_accuracy: 0.1459\n",
      "Epoch 164/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1781 - accuracy: 0.0949 - val_loss: 3.9032 - val_accuracy: 0.1495\n",
      "Epoch 165/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1686 - accuracy: 0.0965 - val_loss: 3.9048 - val_accuracy: 0.1544\n",
      "Epoch 166/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1881 - accuracy: 0.0926 - val_loss: 3.9059 - val_accuracy: 0.1586\n",
      "Epoch 167/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1870 - accuracy: 0.0941 - val_loss: 3.9475 - val_accuracy: 0.1473\n",
      "Epoch 168/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1755 - accuracy: 0.0977 - val_loss: 3.9041 - val_accuracy: 0.1520\n",
      "Epoch 169/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1827 - accuracy: 0.0950 - val_loss: 3.9095 - val_accuracy: 0.1513\n",
      "Epoch 170/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1692 - accuracy: 0.0960 - val_loss: 3.9415 - val_accuracy: 0.1382\n",
      "Epoch 171/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1683 - accuracy: 0.0968 - val_loss: 3.9370 - val_accuracy: 0.1511\n",
      "Epoch 172/1000\n",
      "622/622 [==============================] - 16s 25ms/step - loss: 4.1667 - accuracy: 0.0979 - val_loss: 3.9102 - val_accuracy: 0.1450\n",
      "Epoch 173/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.1766 - accuracy: 0.0964 - val_loss: 3.9116 - val_accuracy: 0.1483\n",
      "Epoch 174/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1617 - accuracy: 0.0966 - val_loss: 3.8991 - val_accuracy: 0.1525\n",
      "Epoch 175/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1689 - accuracy: 0.0978 - val_loss: 3.9732 - val_accuracy: 0.1448\n",
      "Epoch 176/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1670 - accuracy: 0.0937 - val_loss: 3.8923 - val_accuracy: 0.1459\n",
      "Epoch 177/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1850 - accuracy: 0.0924 - val_loss: 3.8722 - val_accuracy: 0.1483\n",
      "Epoch 178/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1669 - accuracy: 0.0958 - val_loss: 3.8819 - val_accuracy: 0.1532\n",
      "Epoch 179/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1731 - accuracy: 0.0936 - val_loss: 3.8348 - val_accuracy: 0.1593\n",
      "Epoch 180/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1837 - accuracy: 0.0967 - val_loss: 3.9434 - val_accuracy: 0.1457\n",
      "Epoch 181/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1785 - accuracy: 0.0932 - val_loss: 3.9107 - val_accuracy: 0.1593\n",
      "Epoch 182/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1626 - accuracy: 0.1008 - val_loss: 3.8745 - val_accuracy: 0.1560\n",
      "Epoch 183/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1551 - accuracy: 0.0979 - val_loss: 3.9102 - val_accuracy: 0.1560\n",
      "Epoch 184/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1789 - accuracy: 0.0966 - val_loss: 3.8739 - val_accuracy: 0.1574\n",
      "Epoch 185/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1556 - accuracy: 0.0963 - val_loss: 3.8841 - val_accuracy: 0.1546\n",
      "Epoch 186/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1871 - accuracy: 0.0975 - val_loss: 3.9756 - val_accuracy: 0.1344\n",
      "Epoch 187/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1706 - accuracy: 0.0961 - val_loss: 3.8901 - val_accuracy: 0.1549\n",
      "Epoch 188/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1520 - accuracy: 0.1020 - val_loss: 3.8643 - val_accuracy: 0.1546\n",
      "Epoch 189/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1634 - accuracy: 0.0952 - val_loss: 3.8997 - val_accuracy: 0.1490\n",
      "Epoch 190/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1570 - accuracy: 0.0995 - val_loss: 3.8684 - val_accuracy: 0.1537\n",
      "Epoch 191/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1553 - accuracy: 0.0978 - val_loss: 3.9129 - val_accuracy: 0.1427\n",
      "Epoch 192/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1453 - accuracy: 0.1021 - val_loss: 3.9290 - val_accuracy: 0.1436\n",
      "Epoch 193/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1517 - accuracy: 0.0993 - val_loss: 3.8615 - val_accuracy: 0.1502\n",
      "Epoch 194/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1730 - accuracy: 0.0965 - val_loss: 3.9355 - val_accuracy: 0.1539\n",
      "Epoch 195/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1484 - accuracy: 0.1003 - val_loss: 3.8651 - val_accuracy: 0.1518\n",
      "Epoch 196/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1640 - accuracy: 0.0935 - val_loss: 3.8918 - val_accuracy: 0.1497\n",
      "Epoch 197/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1582 - accuracy: 0.0969 - val_loss: 3.8975 - val_accuracy: 0.1471\n",
      "Epoch 198/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1460 - accuracy: 0.1016 - val_loss: 3.8821 - val_accuracy: 0.1570\n",
      "Epoch 199/1000\n",
      "622/622 [==============================] - 16s 25ms/step - loss: 4.1675 - accuracy: 0.0957 - val_loss: 3.8798 - val_accuracy: 0.1520\n",
      "Epoch 200/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1532 - accuracy: 0.0997 - val_loss: 3.8541 - val_accuracy: 0.1588\n",
      "Epoch 201/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1367 - accuracy: 0.0990 - val_loss: 3.8589 - val_accuracy: 0.1621\n",
      "Epoch 202/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1542 - accuracy: 0.0984 - val_loss: 3.8853 - val_accuracy: 0.1539\n",
      "Epoch 203/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1617 - accuracy: 0.0994 - val_loss: 3.8768 - val_accuracy: 0.1659\n",
      "Epoch 204/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1650 - accuracy: 0.0980 - val_loss: 3.8398 - val_accuracy: 0.1577\n",
      "Epoch 205/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1569 - accuracy: 0.0984 - val_loss: 3.8520 - val_accuracy: 0.1553\n",
      "Epoch 206/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1534 - accuracy: 0.0976 - val_loss: 3.8610 - val_accuracy: 0.1518\n",
      "Epoch 207/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1524 - accuracy: 0.1008 - val_loss: 3.8780 - val_accuracy: 0.1635\n",
      "Epoch 208/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1671 - accuracy: 0.0934 - val_loss: 3.8708 - val_accuracy: 0.1664\n",
      "Epoch 209/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1454 - accuracy: 0.0969 - val_loss: 3.8686 - val_accuracy: 0.1553\n",
      "Epoch 210/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1519 - accuracy: 0.1004 - val_loss: 3.8524 - val_accuracy: 0.1600\n",
      "Epoch 211/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1401 - accuracy: 0.0992 - val_loss: 3.8648 - val_accuracy: 0.1605\n",
      "Epoch 212/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1306 - accuracy: 0.1005 - val_loss: 3.8967 - val_accuracy: 0.1457\n",
      "Epoch 213/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1388 - accuracy: 0.0988 - val_loss: 3.8853 - val_accuracy: 0.1586\n",
      "Epoch 214/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1359 - accuracy: 0.1002 - val_loss: 3.9055 - val_accuracy: 0.1544\n",
      "Epoch 215/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.1311 - accuracy: 0.1039 - val_loss: 3.8963 - val_accuracy: 0.1556\n",
      "Epoch 216/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1342 - accuracy: 0.1058 - val_loss: 3.8374 - val_accuracy: 0.1542\n",
      "Epoch 217/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1259 - accuracy: 0.1006 - val_loss: 3.8461 - val_accuracy: 0.1581\n",
      "Epoch 218/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1293 - accuracy: 0.1017 - val_loss: 3.8386 - val_accuracy: 0.1666\n",
      "Epoch 219/1000\n",
      "622/622 [==============================] - 16s 25ms/step - loss: 4.1461 - accuracy: 0.1004 - val_loss: 3.8143 - val_accuracy: 0.1624\n",
      "Epoch 220/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.1424 - accuracy: 0.0993 - val_loss: 3.8751 - val_accuracy: 0.1586\n",
      "Epoch 221/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.1358 - accuracy: 0.0984 - val_loss: 3.8540 - val_accuracy: 0.1511\n",
      "Epoch 222/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1325 - accuracy: 0.1038 - val_loss: 3.8812 - val_accuracy: 0.1537\n",
      "Epoch 223/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1285 - accuracy: 0.1037 - val_loss: 3.9027 - val_accuracy: 0.1546\n",
      "Epoch 224/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1380 - accuracy: 0.1027 - val_loss: 3.8348 - val_accuracy: 0.1574\n",
      "Epoch 225/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1367 - accuracy: 0.1033 - val_loss: 3.8576 - val_accuracy: 0.1642\n",
      "Epoch 226/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1191 - accuracy: 0.1000 - val_loss: 3.8571 - val_accuracy: 0.1551\n",
      "Epoch 227/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1181 - accuracy: 0.1009 - val_loss: 3.8697 - val_accuracy: 0.1588\n",
      "Epoch 228/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1264 - accuracy: 0.1024 - val_loss: 3.8157 - val_accuracy: 0.1638\n",
      "Epoch 229/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1346 - accuracy: 0.1006 - val_loss: 3.8056 - val_accuracy: 0.1593\n",
      "Epoch 230/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1347 - accuracy: 0.1001 - val_loss: 3.8355 - val_accuracy: 0.1591\n",
      "Epoch 231/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1346 - accuracy: 0.1006 - val_loss: 3.8424 - val_accuracy: 0.1617\n",
      "Epoch 232/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1372 - accuracy: 0.1002 - val_loss: 3.8487 - val_accuracy: 0.1572\n",
      "Epoch 233/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1310 - accuracy: 0.1029 - val_loss: 3.8767 - val_accuracy: 0.1551\n",
      "Epoch 234/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1205 - accuracy: 0.1054 - val_loss: 3.8953 - val_accuracy: 0.1537\n",
      "Epoch 235/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1315 - accuracy: 0.1051 - val_loss: 3.8471 - val_accuracy: 0.1570\n",
      "Epoch 236/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1209 - accuracy: 0.1021 - val_loss: 3.8276 - val_accuracy: 0.1600\n",
      "Epoch 237/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1306 - accuracy: 0.1027 - val_loss: 3.8372 - val_accuracy: 0.1511\n",
      "Epoch 238/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1132 - accuracy: 0.1038 - val_loss: 3.8454 - val_accuracy: 0.1626\n",
      "Epoch 239/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1236 - accuracy: 0.1022 - val_loss: 3.8576 - val_accuracy: 0.1633\n",
      "Epoch 240/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1231 - accuracy: 0.1054 - val_loss: 3.8133 - val_accuracy: 0.1647\n",
      "Epoch 241/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1293 - accuracy: 0.1018 - val_loss: 3.8312 - val_accuracy: 0.1579\n",
      "Epoch 242/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1344 - accuracy: 0.1011 - val_loss: 3.8926 - val_accuracy: 0.1588\n",
      "Epoch 243/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1348 - accuracy: 0.1010 - val_loss: 3.8529 - val_accuracy: 0.1525\n",
      "Epoch 244/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1276 - accuracy: 0.1015 - val_loss: 3.8147 - val_accuracy: 0.1610\n",
      "Epoch 245/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1247 - accuracy: 0.1010 - val_loss: 3.8264 - val_accuracy: 0.1692\n",
      "Epoch 246/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1142 - accuracy: 0.1025 - val_loss: 3.9006 - val_accuracy: 0.1483\n",
      "Epoch 247/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1223 - accuracy: 0.1052 - val_loss: 3.8658 - val_accuracy: 0.1659\n",
      "Epoch 248/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1200 - accuracy: 0.1024 - val_loss: 3.8530 - val_accuracy: 0.1591\n",
      "Epoch 249/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1157 - accuracy: 0.1045 - val_loss: 3.7780 - val_accuracy: 0.1734\n",
      "Epoch 250/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0993 - accuracy: 0.1030 - val_loss: 3.8541 - val_accuracy: 0.1518\n",
      "Epoch 251/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1174 - accuracy: 0.1026 - val_loss: 3.8589 - val_accuracy: 0.1506\n",
      "Epoch 252/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1215 - accuracy: 0.1054 - val_loss: 3.8660 - val_accuracy: 0.1598\n",
      "Epoch 253/1000\n",
      "622/622 [==============================] - 14s 22ms/step - loss: 4.1037 - accuracy: 0.1072 - val_loss: 3.8023 - val_accuracy: 0.1645\n",
      "Epoch 254/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1170 - accuracy: 0.1032 - val_loss: 3.8048 - val_accuracy: 0.1659\n",
      "Epoch 255/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1265 - accuracy: 0.1032 - val_loss: 3.8022 - val_accuracy: 0.1701\n",
      "Epoch 256/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1150 - accuracy: 0.1041 - val_loss: 3.8138 - val_accuracy: 0.1687\n",
      "Epoch 257/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1169 - accuracy: 0.1034 - val_loss: 3.8405 - val_accuracy: 0.1619\n",
      "Epoch 258/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1069 - accuracy: 0.1037 - val_loss: 3.9100 - val_accuracy: 0.1614\n",
      "Epoch 259/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1216 - accuracy: 0.1020 - val_loss: 3.8412 - val_accuracy: 0.1619\n",
      "Epoch 260/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1148 - accuracy: 0.1025 - val_loss: 3.8453 - val_accuracy: 0.1532\n",
      "Epoch 261/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1258 - accuracy: 0.1039 - val_loss: 3.8388 - val_accuracy: 0.1612\n",
      "Epoch 262/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1299 - accuracy: 0.1034 - val_loss: 3.8489 - val_accuracy: 0.1647\n",
      "Epoch 263/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1083 - accuracy: 0.1032 - val_loss: 3.8736 - val_accuracy: 0.1631\n",
      "Epoch 264/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.1180 - accuracy: 0.1064 - val_loss: 3.8258 - val_accuracy: 0.1640\n",
      "Epoch 265/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.1083 - accuracy: 0.1053 - val_loss: 3.7938 - val_accuracy: 0.1656\n",
      "Epoch 266/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1087 - accuracy: 0.1031 - val_loss: 3.8027 - val_accuracy: 0.1687\n",
      "Epoch 267/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1196 - accuracy: 0.1061 - val_loss: 3.8435 - val_accuracy: 0.1675\n",
      "Epoch 268/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1049 - accuracy: 0.1056 - val_loss: 3.8478 - val_accuracy: 0.1666\n",
      "Epoch 269/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1077 - accuracy: 0.1069 - val_loss: 3.8073 - val_accuracy: 0.1628\n",
      "Epoch 270/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1105 - accuracy: 0.1048 - val_loss: 3.7824 - val_accuracy: 0.1668\n",
      "Epoch 271/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1095 - accuracy: 0.1042 - val_loss: 3.8241 - val_accuracy: 0.1689\n",
      "Epoch 272/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1073 - accuracy: 0.1052 - val_loss: 3.7762 - val_accuracy: 0.1682\n",
      "Epoch 273/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0976 - accuracy: 0.1070 - val_loss: 3.8077 - val_accuracy: 0.1762\n",
      "Epoch 274/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1073 - accuracy: 0.1072 - val_loss: 3.8339 - val_accuracy: 0.1675\n",
      "Epoch 275/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1142 - accuracy: 0.1062 - val_loss: 3.7533 - val_accuracy: 0.1776\n",
      "Epoch 276/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1155 - accuracy: 0.1032 - val_loss: 3.8326 - val_accuracy: 0.1802\n",
      "Epoch 277/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1149 - accuracy: 0.1045 - val_loss: 3.8398 - val_accuracy: 0.1692\n",
      "Epoch 278/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0993 - accuracy: 0.1066 - val_loss: 3.8322 - val_accuracy: 0.1675\n",
      "Epoch 279/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1037 - accuracy: 0.1095 - val_loss: 3.8542 - val_accuracy: 0.1628\n",
      "Epoch 280/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0874 - accuracy: 0.1085 - val_loss: 3.7984 - val_accuracy: 0.1631\n",
      "Epoch 281/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1022 - accuracy: 0.1072 - val_loss: 3.8739 - val_accuracy: 0.1642\n",
      "Epoch 282/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1003 - accuracy: 0.1081 - val_loss: 3.8315 - val_accuracy: 0.1631\n",
      "Epoch 283/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0986 - accuracy: 0.1067 - val_loss: 3.8312 - val_accuracy: 0.1694\n",
      "Epoch 284/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0992 - accuracy: 0.1105 - val_loss: 3.7891 - val_accuracy: 0.1741\n",
      "Epoch 285/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1098 - accuracy: 0.1040 - val_loss: 3.7506 - val_accuracy: 0.1790\n",
      "Epoch 286/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0950 - accuracy: 0.1083 - val_loss: 3.8067 - val_accuracy: 0.1703\n",
      "Epoch 287/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1016 - accuracy: 0.1047 - val_loss: 3.9202 - val_accuracy: 0.1668\n",
      "Epoch 288/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1122 - accuracy: 0.1021 - val_loss: 3.8003 - val_accuracy: 0.1682\n",
      "Epoch 289/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1109 - accuracy: 0.1053 - val_loss: 3.8548 - val_accuracy: 0.1675\n",
      "Epoch 290/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1023 - accuracy: 0.1074 - val_loss: 3.8166 - val_accuracy: 0.1668\n",
      "Epoch 291/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0855 - accuracy: 0.1069 - val_loss: 3.8224 - val_accuracy: 0.1673\n",
      "Epoch 292/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1100 - accuracy: 0.1039 - val_loss: 3.8070 - val_accuracy: 0.1722\n",
      "Epoch 293/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0975 - accuracy: 0.1086 - val_loss: 3.7664 - val_accuracy: 0.1816\n",
      "Epoch 294/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1152 - accuracy: 0.1066 - val_loss: 3.8021 - val_accuracy: 0.1727\n",
      "Epoch 295/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1112 - accuracy: 0.1061 - val_loss: 3.8312 - val_accuracy: 0.1692\n",
      "Epoch 296/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1150 - accuracy: 0.1035 - val_loss: 3.8063 - val_accuracy: 0.1746\n",
      "Epoch 297/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0936 - accuracy: 0.1060 - val_loss: 3.7730 - val_accuracy: 0.1802\n",
      "Epoch 298/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0951 - accuracy: 0.1094 - val_loss: 3.8917 - val_accuracy: 0.1610\n",
      "Epoch 299/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0951 - accuracy: 0.1072 - val_loss: 3.7993 - val_accuracy: 0.1703\n",
      "Epoch 300/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1054 - accuracy: 0.1053 - val_loss: 3.7817 - val_accuracy: 0.1767\n",
      "Epoch 301/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0896 - accuracy: 0.1076 - val_loss: 3.8185 - val_accuracy: 0.1687\n",
      "Epoch 302/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0929 - accuracy: 0.1081 - val_loss: 3.8261 - val_accuracy: 0.1652\n",
      "Epoch 303/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0952 - accuracy: 0.1078 - val_loss: 3.7528 - val_accuracy: 0.1732\n",
      "Epoch 304/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1051 - accuracy: 0.1088 - val_loss: 3.9167 - val_accuracy: 0.1607\n",
      "Epoch 305/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.0975 - accuracy: 0.1059 - val_loss: 3.8185 - val_accuracy: 0.1666\n",
      "Epoch 306/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0968 - accuracy: 0.1091 - val_loss: 3.8155 - val_accuracy: 0.1682\n",
      "Epoch 307/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0945 - accuracy: 0.1091 - val_loss: 3.8142 - val_accuracy: 0.1692\n",
      "Epoch 308/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1051 - accuracy: 0.1056 - val_loss: 3.8605 - val_accuracy: 0.1603\n",
      "Epoch 309/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1054 - accuracy: 0.1094 - val_loss: 3.8043 - val_accuracy: 0.1687\n",
      "Epoch 310/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.0952 - accuracy: 0.1096 - val_loss: 3.8742 - val_accuracy: 0.1497\n",
      "Epoch 311/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1025 - accuracy: 0.1053 - val_loss: 3.7501 - val_accuracy: 0.1790\n",
      "Epoch 312/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1018 - accuracy: 0.1091 - val_loss: 3.8471 - val_accuracy: 0.1635\n",
      "Epoch 313/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0970 - accuracy: 0.1050 - val_loss: 3.7884 - val_accuracy: 0.1757\n",
      "Epoch 314/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0976 - accuracy: 0.1090 - val_loss: 3.7966 - val_accuracy: 0.1750\n",
      "Epoch 315/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0841 - accuracy: 0.1072 - val_loss: 3.8997 - val_accuracy: 0.1549\n",
      "Epoch 316/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.0926 - accuracy: 0.1062 - val_loss: 3.7994 - val_accuracy: 0.1617\n",
      "Epoch 317/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0937 - accuracy: 0.1031 - val_loss: 3.7925 - val_accuracy: 0.1703\n",
      "Epoch 318/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.1108 - accuracy: 0.1076 - val_loss: 3.7778 - val_accuracy: 0.1713\n",
      "Epoch 319/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0850 - accuracy: 0.1081 - val_loss: 3.7301 - val_accuracy: 0.1734\n",
      "Epoch 320/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0884 - accuracy: 0.1100 - val_loss: 3.7727 - val_accuracy: 0.1764\n",
      "Epoch 321/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0881 - accuracy: 0.1076 - val_loss: 3.8010 - val_accuracy: 0.1638\n",
      "Epoch 322/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.0794 - accuracy: 0.1101 - val_loss: 3.7956 - val_accuracy: 0.1727\n",
      "Epoch 323/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0985 - accuracy: 0.1056 - val_loss: 3.8969 - val_accuracy: 0.1504\n",
      "Epoch 324/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0708 - accuracy: 0.1097 - val_loss: 3.8334 - val_accuracy: 0.1741\n",
      "Epoch 325/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0876 - accuracy: 0.1108 - val_loss: 3.7843 - val_accuracy: 0.1656\n",
      "Epoch 326/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0785 - accuracy: 0.1087 - val_loss: 3.8503 - val_accuracy: 0.1642\n",
      "Epoch 327/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0972 - accuracy: 0.1080 - val_loss: 3.8166 - val_accuracy: 0.1696\n",
      "Epoch 328/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0961 - accuracy: 0.1096 - val_loss: 3.8504 - val_accuracy: 0.1741\n",
      "Epoch 329/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0931 - accuracy: 0.1069 - val_loss: 3.7577 - val_accuracy: 0.1793\n",
      "Epoch 330/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0830 - accuracy: 0.1100 - val_loss: 3.7289 - val_accuracy: 0.1788\n",
      "Epoch 331/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0922 - accuracy: 0.1042 - val_loss: 3.8263 - val_accuracy: 0.1656\n",
      "Epoch 332/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0955 - accuracy: 0.1078 - val_loss: 3.9182 - val_accuracy: 0.1649\n",
      "Epoch 333/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0764 - accuracy: 0.1066 - val_loss: 3.7736 - val_accuracy: 0.1694\n",
      "Epoch 334/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0869 - accuracy: 0.1058 - val_loss: 3.7470 - val_accuracy: 0.1771\n",
      "Epoch 335/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0818 - accuracy: 0.1122 - val_loss: 3.8030 - val_accuracy: 0.1715\n",
      "Epoch 336/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0821 - accuracy: 0.1056 - val_loss: 3.8195 - val_accuracy: 0.1753\n",
      "Epoch 337/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0856 - accuracy: 0.1079 - val_loss: 3.8283 - val_accuracy: 0.1680\n",
      "Epoch 338/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0893 - accuracy: 0.1080 - val_loss: 3.7967 - val_accuracy: 0.1633\n",
      "Epoch 339/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0828 - accuracy: 0.1074 - val_loss: 3.8584 - val_accuracy: 0.1626\n",
      "Epoch 340/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0775 - accuracy: 0.1065 - val_loss: 3.7828 - val_accuracy: 0.1720\n",
      "Epoch 341/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0908 - accuracy: 0.1084 - val_loss: 3.7839 - val_accuracy: 0.1800\n",
      "Epoch 342/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0828 - accuracy: 0.1080 - val_loss: 3.7162 - val_accuracy: 0.1816\n",
      "Epoch 343/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0678 - accuracy: 0.1113 - val_loss: 3.8042 - val_accuracy: 0.1748\n",
      "Epoch 344/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0693 - accuracy: 0.1110 - val_loss: 3.8234 - val_accuracy: 0.1692\n",
      "Epoch 345/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0877 - accuracy: 0.1076 - val_loss: 3.8015 - val_accuracy: 0.1685\n",
      "Epoch 346/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0799 - accuracy: 0.1070 - val_loss: 3.7363 - val_accuracy: 0.1863\n",
      "Epoch 347/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0808 - accuracy: 0.1067 - val_loss: 3.7895 - val_accuracy: 0.1764\n",
      "Epoch 348/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0934 - accuracy: 0.1067 - val_loss: 3.8053 - val_accuracy: 0.1779\n",
      "Epoch 349/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0820 - accuracy: 0.1091 - val_loss: 3.7696 - val_accuracy: 0.1741\n",
      "Epoch 350/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0713 - accuracy: 0.1101 - val_loss: 3.7459 - val_accuracy: 0.1816\n",
      "Epoch 351/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0691 - accuracy: 0.1116 - val_loss: 3.8643 - val_accuracy: 0.1520\n",
      "Epoch 352/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0787 - accuracy: 0.1078 - val_loss: 3.8542 - val_accuracy: 0.1795\n",
      "Epoch 353/1000\n",
      "622/622 [==============================] - 15s 25ms/step - loss: 4.0932 - accuracy: 0.1093 - val_loss: 3.7882 - val_accuracy: 0.1687\n",
      "Epoch 354/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0918 - accuracy: 0.1075 - val_loss: 3.8282 - val_accuracy: 0.1760\n",
      "Epoch 355/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0730 - accuracy: 0.1112 - val_loss: 3.8017 - val_accuracy: 0.1762\n",
      "Epoch 356/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0850 - accuracy: 0.1110 - val_loss: 3.7366 - val_accuracy: 0.1769\n",
      "Epoch 357/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0791 - accuracy: 0.1102 - val_loss: 3.7938 - val_accuracy: 0.1729\n",
      "Epoch 358/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0749 - accuracy: 0.1057 - val_loss: 3.8603 - val_accuracy: 0.1551\n",
      "Epoch 359/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0732 - accuracy: 0.1089 - val_loss: 3.7685 - val_accuracy: 0.1718\n",
      "Epoch 360/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.1005 - accuracy: 0.1069 - val_loss: 3.7810 - val_accuracy: 0.1771\n",
      "Epoch 361/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0871 - accuracy: 0.1093 - val_loss: 3.8181 - val_accuracy: 0.1736\n",
      "Epoch 362/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0769 - accuracy: 0.1113 - val_loss: 3.8061 - val_accuracy: 0.1746\n",
      "Epoch 363/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0734 - accuracy: 0.1089 - val_loss: 3.7741 - val_accuracy: 0.1699\n",
      "Epoch 364/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0667 - accuracy: 0.1116 - val_loss: 3.7640 - val_accuracy: 0.1776\n",
      "Epoch 365/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0593 - accuracy: 0.1101 - val_loss: 3.8261 - val_accuracy: 0.1654\n",
      "Epoch 366/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0753 - accuracy: 0.1116 - val_loss: 3.8301 - val_accuracy: 0.1713\n",
      "Epoch 367/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0773 - accuracy: 0.1098 - val_loss: 3.7965 - val_accuracy: 0.1610\n",
      "Epoch 368/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0659 - accuracy: 0.1130 - val_loss: 3.8200 - val_accuracy: 0.1673\n",
      "Epoch 369/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0712 - accuracy: 0.1107 - val_loss: 3.7713 - val_accuracy: 0.1818\n",
      "Epoch 370/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0725 - accuracy: 0.1125 - val_loss: 3.7899 - val_accuracy: 0.1832\n",
      "Epoch 371/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0847 - accuracy: 0.1081 - val_loss: 3.7695 - val_accuracy: 0.1879\n",
      "Epoch 372/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0723 - accuracy: 0.1119 - val_loss: 3.7005 - val_accuracy: 0.1837\n",
      "Epoch 373/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0783 - accuracy: 0.1097 - val_loss: 3.7677 - val_accuracy: 0.1746\n",
      "Epoch 374/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0838 - accuracy: 0.1087 - val_loss: 3.7942 - val_accuracy: 0.1701\n",
      "Epoch 375/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0701 - accuracy: 0.1102 - val_loss: 3.7462 - val_accuracy: 0.1818\n",
      "Epoch 376/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0752 - accuracy: 0.1076 - val_loss: 3.7847 - val_accuracy: 0.1736\n",
      "Epoch 377/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0715 - accuracy: 0.1078 - val_loss: 3.7556 - val_accuracy: 0.1755\n",
      "Epoch 378/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0645 - accuracy: 0.1111 - val_loss: 3.7712 - val_accuracy: 0.1720\n",
      "Epoch 379/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0730 - accuracy: 0.1105 - val_loss: 3.6873 - val_accuracy: 0.1886\n",
      "Epoch 380/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0620 - accuracy: 0.1106 - val_loss: 3.7587 - val_accuracy: 0.1795\n",
      "Epoch 381/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0692 - accuracy: 0.1109 - val_loss: 3.7922 - val_accuracy: 0.1727\n",
      "Epoch 382/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0897 - accuracy: 0.1112 - val_loss: 3.7650 - val_accuracy: 0.1727\n",
      "Epoch 383/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0656 - accuracy: 0.1116 - val_loss: 3.7065 - val_accuracy: 0.1847\n",
      "Epoch 384/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0740 - accuracy: 0.1093 - val_loss: 3.7855 - val_accuracy: 0.1814\n",
      "Epoch 385/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0793 - accuracy: 0.1096 - val_loss: 3.7506 - val_accuracy: 0.1908\n",
      "Epoch 386/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0648 - accuracy: 0.1123 - val_loss: 3.7590 - val_accuracy: 0.1774\n",
      "Epoch 387/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0784 - accuracy: 0.1087 - val_loss: 3.8010 - val_accuracy: 0.1682\n",
      "Epoch 388/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0696 - accuracy: 0.1138 - val_loss: 3.7566 - val_accuracy: 0.1779\n",
      "Epoch 389/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0828 - accuracy: 0.1130 - val_loss: 3.7477 - val_accuracy: 0.1821\n",
      "Epoch 390/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0553 - accuracy: 0.1129 - val_loss: 3.8473 - val_accuracy: 0.1807\n",
      "Epoch 391/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0689 - accuracy: 0.1084 - val_loss: 3.8183 - val_accuracy: 0.1804\n",
      "Epoch 392/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0751 - accuracy: 0.1111 - val_loss: 3.7235 - val_accuracy: 0.1863\n",
      "Epoch 393/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0833 - accuracy: 0.1133 - val_loss: 3.7648 - val_accuracy: 0.1746\n",
      "Epoch 394/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0587 - accuracy: 0.1100 - val_loss: 3.7151 - val_accuracy: 0.1781\n",
      "Epoch 395/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0640 - accuracy: 0.1117 - val_loss: 3.7357 - val_accuracy: 0.1779\n",
      "Epoch 396/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0799 - accuracy: 0.1103 - val_loss: 3.7413 - val_accuracy: 0.1804\n",
      "Epoch 397/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0745 - accuracy: 0.1117 - val_loss: 3.8491 - val_accuracy: 0.1685\n",
      "Epoch 398/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0484 - accuracy: 0.1119 - val_loss: 3.8260 - val_accuracy: 0.1652\n",
      "Epoch 399/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0835 - accuracy: 0.1097 - val_loss: 3.8303 - val_accuracy: 0.1713\n",
      "Epoch 400/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0498 - accuracy: 0.1119 - val_loss: 3.7853 - val_accuracy: 0.1762\n",
      "Epoch 401/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0868 - accuracy: 0.1100 - val_loss: 3.7616 - val_accuracy: 0.1865\n",
      "Epoch 402/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0696 - accuracy: 0.1120 - val_loss: 3.7261 - val_accuracy: 0.1800\n",
      "Epoch 403/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0576 - accuracy: 0.1137 - val_loss: 3.7943 - val_accuracy: 0.1678\n",
      "Epoch 404/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0616 - accuracy: 0.1129 - val_loss: 3.7653 - val_accuracy: 0.1708\n",
      "Epoch 405/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0570 - accuracy: 0.1135 - val_loss: 3.7714 - val_accuracy: 0.1734\n",
      "Epoch 406/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0933 - accuracy: 0.1085 - val_loss: 3.7996 - val_accuracy: 0.1692\n",
      "Epoch 407/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0628 - accuracy: 0.1122 - val_loss: 3.7292 - val_accuracy: 0.1825\n",
      "Epoch 408/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0628 - accuracy: 0.1119 - val_loss: 3.8043 - val_accuracy: 0.1734\n",
      "Epoch 409/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0675 - accuracy: 0.1107 - val_loss: 3.7408 - val_accuracy: 0.1776\n",
      "Epoch 410/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0626 - accuracy: 0.1086 - val_loss: 3.7749 - val_accuracy: 0.1664\n",
      "Epoch 411/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0678 - accuracy: 0.1087 - val_loss: 3.8207 - val_accuracy: 0.1675\n",
      "Epoch 412/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.1071 - accuracy: 0.1049 - val_loss: 3.8083 - val_accuracy: 0.1734\n",
      "Epoch 413/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0761 - accuracy: 0.1086 - val_loss: 3.7197 - val_accuracy: 0.1849\n",
      "Epoch 414/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0529 - accuracy: 0.1156 - val_loss: 3.7429 - val_accuracy: 0.1781\n",
      "Epoch 415/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0623 - accuracy: 0.1110 - val_loss: 3.8269 - val_accuracy: 0.1675\n",
      "Epoch 416/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0658 - accuracy: 0.1107 - val_loss: 3.8023 - val_accuracy: 0.1802\n",
      "Epoch 417/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0630 - accuracy: 0.1092 - val_loss: 3.7711 - val_accuracy: 0.1720\n",
      "Epoch 418/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0713 - accuracy: 0.1087 - val_loss: 3.7664 - val_accuracy: 0.1757\n",
      "Epoch 419/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0647 - accuracy: 0.1109 - val_loss: 3.7981 - val_accuracy: 0.1849\n",
      "Epoch 420/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0778 - accuracy: 0.1094 - val_loss: 3.7424 - val_accuracy: 0.1800\n",
      "Epoch 421/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0676 - accuracy: 0.1105 - val_loss: 3.7570 - val_accuracy: 0.1919\n",
      "Epoch 422/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0633 - accuracy: 0.1138 - val_loss: 3.7929 - val_accuracy: 0.1912\n",
      "Epoch 423/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0729 - accuracy: 0.1105 - val_loss: 3.8061 - val_accuracy: 0.1727\n",
      "Epoch 424/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0671 - accuracy: 0.1087 - val_loss: 3.7936 - val_accuracy: 0.1671\n",
      "Epoch 425/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0799 - accuracy: 0.1095 - val_loss: 3.7756 - val_accuracy: 0.1734\n",
      "Epoch 426/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0748 - accuracy: 0.1081 - val_loss: 3.8631 - val_accuracy: 0.1614\n",
      "Epoch 427/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0804 - accuracy: 0.1088 - val_loss: 3.7336 - val_accuracy: 0.1823\n",
      "Epoch 428/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0496 - accuracy: 0.1111 - val_loss: 3.8027 - val_accuracy: 0.1753\n",
      "Epoch 429/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0669 - accuracy: 0.1107 - val_loss: 3.7717 - val_accuracy: 0.1727\n",
      "Epoch 430/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0591 - accuracy: 0.1143 - val_loss: 3.7936 - val_accuracy: 0.1764\n",
      "Epoch 431/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0672 - accuracy: 0.1146 - val_loss: 3.7439 - val_accuracy: 0.1774\n",
      "Epoch 432/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0606 - accuracy: 0.1104 - val_loss: 3.7873 - val_accuracy: 0.1734\n",
      "Epoch 433/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0730 - accuracy: 0.1104 - val_loss: 3.8700 - val_accuracy: 0.1551\n",
      "Epoch 434/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0749 - accuracy: 0.1098 - val_loss: 3.7745 - val_accuracy: 0.1729\n",
      "Epoch 435/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0719 - accuracy: 0.1105 - val_loss: 3.7539 - val_accuracy: 0.1760\n",
      "Epoch 436/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0694 - accuracy: 0.1090 - val_loss: 3.7660 - val_accuracy: 0.1685\n",
      "Epoch 437/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0664 - accuracy: 0.1127 - val_loss: 3.7932 - val_accuracy: 0.1741\n",
      "Epoch 438/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0682 - accuracy: 0.1084 - val_loss: 3.7954 - val_accuracy: 0.1800\n",
      "Epoch 439/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0526 - accuracy: 0.1151 - val_loss: 3.7420 - val_accuracy: 0.1786\n",
      "Epoch 440/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0692 - accuracy: 0.1100 - val_loss: 3.7516 - val_accuracy: 0.1908\n",
      "Epoch 441/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0643 - accuracy: 0.1078 - val_loss: 3.7033 - val_accuracy: 0.1912\n",
      "Epoch 442/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0697 - accuracy: 0.1081 - val_loss: 3.7474 - val_accuracy: 0.1800\n",
      "Epoch 443/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0588 - accuracy: 0.1119 - val_loss: 3.7457 - val_accuracy: 0.1769\n",
      "Epoch 444/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0632 - accuracy: 0.1153 - val_loss: 3.7771 - val_accuracy: 0.1734\n",
      "Epoch 445/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0661 - accuracy: 0.1139 - val_loss: 3.7825 - val_accuracy: 0.1795\n",
      "Epoch 446/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0606 - accuracy: 0.1081 - val_loss: 3.7346 - val_accuracy: 0.1804\n",
      "Epoch 447/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0705 - accuracy: 0.1113 - val_loss: 3.7146 - val_accuracy: 0.1835\n",
      "Epoch 448/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0494 - accuracy: 0.1135 - val_loss: 3.7714 - val_accuracy: 0.1732\n",
      "Epoch 449/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0641 - accuracy: 0.1122 - val_loss: 3.7651 - val_accuracy: 0.1713\n",
      "Epoch 450/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0577 - accuracy: 0.1141 - val_loss: 3.6934 - val_accuracy: 0.1760\n",
      "Epoch 451/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0639 - accuracy: 0.1152 - val_loss: 3.7630 - val_accuracy: 0.1823\n",
      "Epoch 452/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0576 - accuracy: 0.1164 - val_loss: 3.7312 - val_accuracy: 0.1879\n",
      "Epoch 453/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0421 - accuracy: 0.1145 - val_loss: 3.7903 - val_accuracy: 0.1736\n",
      "Epoch 454/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0737 - accuracy: 0.1116 - val_loss: 3.7911 - val_accuracy: 0.1739\n",
      "Epoch 455/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0611 - accuracy: 0.1098 - val_loss: 3.7570 - val_accuracy: 0.1781\n",
      "Epoch 456/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0761 - accuracy: 0.1073 - val_loss: 3.7781 - val_accuracy: 0.1720\n",
      "Epoch 457/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0718 - accuracy: 0.1092 - val_loss: 3.7302 - val_accuracy: 0.1830\n",
      "Epoch 458/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0651 - accuracy: 0.1125 - val_loss: 3.7429 - val_accuracy: 0.1825\n",
      "Epoch 459/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0705 - accuracy: 0.1133 - val_loss: 3.7574 - val_accuracy: 0.1797\n",
      "Epoch 460/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0676 - accuracy: 0.1117 - val_loss: 3.7917 - val_accuracy: 0.1750\n",
      "Epoch 461/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0550 - accuracy: 0.1130 - val_loss: 3.7684 - val_accuracy: 0.1811\n",
      "Epoch 462/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0718 - accuracy: 0.1087 - val_loss: 3.7558 - val_accuracy: 0.1722\n",
      "Epoch 463/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0632 - accuracy: 0.1138 - val_loss: 3.7007 - val_accuracy: 0.1790\n",
      "Epoch 464/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0649 - accuracy: 0.1119 - val_loss: 3.7597 - val_accuracy: 0.1739\n",
      "Epoch 465/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0646 - accuracy: 0.1088 - val_loss: 3.7193 - val_accuracy: 0.1797\n",
      "Epoch 466/1000\n",
      "622/622 [==============================] - 14s 23ms/step - loss: 4.0613 - accuracy: 0.1125 - val_loss: 3.7300 - val_accuracy: 0.1790\n",
      "Epoch 467/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0467 - accuracy: 0.1124 - val_loss: 3.8110 - val_accuracy: 0.1722\n",
      "Epoch 468/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0876 - accuracy: 0.1072 - val_loss: 3.7146 - val_accuracy: 0.1868\n",
      "Epoch 469/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0643 - accuracy: 0.1125 - val_loss: 3.7424 - val_accuracy: 0.1847\n",
      "Epoch 470/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0723 - accuracy: 0.1128 - val_loss: 3.7980 - val_accuracy: 0.1818\n",
      "Epoch 471/1000\n",
      "622/622 [==============================] - 15s 23ms/step - loss: 4.0800 - accuracy: 0.1127 - val_loss: 3.7675 - val_accuracy: 0.1849\n",
      "Epoch 472/1000\n",
      "622/622 [==============================] - 15s 24ms/step - loss: 4.0802 - accuracy: 0.1111 - val_loss: 3.7869 - val_accuracy: 0.1671\n",
      "Epoch 473/1000\n",
      "269/622 [===========>..................] - ETA: 7s - loss: 4.0562 - accuracy: 0.1105"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_datagen\u001b[39m.\u001b[39;49mflow(train_images, train_labels, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m), epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(val_images, val_labels))\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_datagen.flow(train_images, train_labels, batch_size=32), epochs=1000, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
