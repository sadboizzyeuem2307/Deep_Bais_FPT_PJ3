{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = 64, 64\n",
    "num_classes = 164\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((image_width, image_height))\n",
    "    img = np.array(img)\n",
    "    img = img / 255.0  \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'D:\\Project3\\tai\\EarVN1.0 dataset\\Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_mapping = {}\n",
    "class_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in os.listdir(dataset_path):\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if not os.path.isdir(class_folder):\n",
    "        continue\n",
    "    class_label_mapping[class_name] = class_count\n",
    "    class_count += 1\n",
    "\n",
    "    for image_name in os.listdir(class_folder):\n",
    "        image_path = os.path.join(class_folder, image_name)\n",
    "        img = preprocess_image(image_path)\n",
    "        images.append(img)\n",
    "        labels.append(class_label_mapping[class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'001.ALI_HD': 0,\n",
       " '002.LeDuong_BL': 1,\n",
       " '003.BD_Tran': 2,\n",
       " '004.Binz': 3,\n",
       " '005.Bui_AT': 4,\n",
       " '006.Chau_GK': 5,\n",
       " '007.Chau_KP': 6,\n",
       " '008.Chi_D': 7,\n",
       " '009.Chi_Th': 8,\n",
       " '010.Chu_B': 9,\n",
       " '011.Cong_To': 10,\n",
       " '012.Dai_Nhan': 11,\n",
       " '013.Dam_Vinh_H': 12,\n",
       " '014.Dan_Ng': 13,\n",
       " '015.Dan_Trg': 14,\n",
       " '016.Dang_L': 15,\n",
       " '017.Dao_Ba_L': 16,\n",
       " '018.De_C': 17,\n",
       " '019.Don_Ng': 18,\n",
       " '020.Duong_D': 19,\n",
       " '021.Dustin_Phuc_Ng': 20,\n",
       " '022.Duy_Kh': 21,\n",
       " '023.Erik': 22,\n",
       " '024.Gin_Tuan_K': 23,\n",
       " '025.Ha_Anh_T': 24,\n",
       " '026.Hac_Hoa_K': 25,\n",
       " '027.Hamtet_Tr': 26,\n",
       " '028.Ho_Quang_H': 27,\n",
       " '029.Ho_Trung_D': 28,\n",
       " '030.Hoai_L': 29,\n",
       " '031.Hoang_Rap': 30,\n",
       " '032.Huy_Tr': 31,\n",
       " '033.Huynh_L': 32,\n",
       " '034.Huynh_Ph': 33,\n",
       " '035.Isaac': 34,\n",
       " '036.Jun_Ph': 35,\n",
       " '037.Justatee': 36,\n",
       " '038.Kenvin_Kh': 37,\n",
       " '039.KhacVi': 38,\n",
       " '040.Khuong_Ng': 39,\n",
       " '041.Kieu_Minh_T': 40,\n",
       " '042.Kim_L': 41,\n",
       " '043.L_HA': 42,\n",
       " '044.Lam_Canh_T': 43,\n",
       " '045.Lam_Hu': 44,\n",
       " '046.Lam_Tr': 45,\n",
       " '047.Lam_Vinh_H': 46,\n",
       " '048.Lee_Jong_S': 47,\n",
       " '049.Lee_Min_H': 48,\n",
       " '050.Long_Nh': 49,\n",
       " '051.Lou_Ho': 50,\n",
       " '052.Luong_Bang_Q': 51,\n",
       " '053.Luong_Manh_H': 52,\n",
       " '054.Luong_The_Th': 53,\n",
       " '055.Ly_Dich_P': 54,\n",
       " '056.Mai_Tai_Ph': 55,\n",
       " '057.Nam_Cuog': 56,\n",
       " '058.Ngo_Diec_P': 57,\n",
       " '059.Ngo_Kien_H': 58,\n",
       " '060.Nguyen_Khang': 59,\n",
       " '061.Nguyen_Phi_Hu': 60,\n",
       " '062.Nguyen_Tran_Trung_Qu': 61,\n",
       " '063.Nhan_Phuc_V': 62,\n",
       " '064.Noo_Phuoc_Th': 63,\n",
       " '065.Ong_Cao_Th': 64,\n",
       " '066.OnlyC': 65,\n",
       " '067.Pham_Hong_Ph': 66,\n",
       " '068.Pham_Tr': 67,\n",
       " '069.Phan_A': 68,\n",
       " '070.Phan_M_Quy': 69,\n",
       " '071.Quang_B': 70,\n",
       " '072.Quang_Ha': 71,\n",
       " '073.Quang_Tr': 72,\n",
       " '074.Quy_B': 73,\n",
       " '075.Rym': 74,\n",
       " '076.Sky_ST': 75,\n",
       " '077.Soobin_HS': 76,\n",
       " '078.ST': 77,\n",
       " '079.Ta_Quang_T': 78,\n",
       " '080.Thai_V': 79,\n",
       " '081.Thanh_D': 80,\n",
       " '082.Thanh_Lo': 81,\n",
       " '083.ThanhTr': 82,\n",
       " '084.TIM': 83,\n",
       " '085.Toulive': 84,\n",
       " '086.Tran Dinh Q': 85,\n",
       " '087.Tran Th': 86,\n",
       " '088.Trinh_Thang_B': 87,\n",
       " '089.Trong_Hie': 88,\n",
       " '090.Truc_nh': 89,\n",
       " '091.TrungQua': 90,\n",
       " '092.TruonGNam_th': 91,\n",
       " '093.TruongThe_V': 92,\n",
       " '094.Tuan_Hu': 93,\n",
       " '095.Tung_Dg': 94,\n",
       " '096.Ung_DaiV': 95,\n",
       " '097.UngHoaP': 96,\n",
       " '098.V_rau': 97,\n",
       " '099.Amber': 98,\n",
       " '100.Angela_Ba': 99,\n",
       " '101.Cao_Ng': 100,\n",
       " '102.Cao_Thien_Tr': 101,\n",
       " '103.Cha_Mi': 102,\n",
       " '104.Chau_B': 103,\n",
       " '105.Dich_Le_Nhiet': 104,\n",
       " '106.Do_My_L': 105,\n",
       " '107.Duong_M': 106,\n",
       " '108.Gil_L': 107,\n",
       " '109.Go_Joon_H': 108,\n",
       " '110.H_Hen_N': 109,\n",
       " '111.Hang_Ng': 110,\n",
       " '112.IU': 111,\n",
       " '113.Khong_Tu_Qu': 112,\n",
       " '114.Kieu_Tr': 113,\n",
       " '115.Kim_Hye_S': 114,\n",
       " '116.Kim_Ji_W': 115,\n",
       " '117.Kim_Ng': 116,\n",
       " '118.Kim_Nh': 117,\n",
       " '119.Kim_Ph': 118,\n",
       " '120.Kim_So_H': 119,\n",
       " '121.Kim_Yoo_J': 120,\n",
       " '122.La_Thanh_H': 121,\n",
       " '123.Lan_Kh': 122,\n",
       " '124.Le_Cat_Trong_L': 123,\n",
       " '125.Le_Ph': 124,\n",
       " '126.Le_Thanh_Th': 125,\n",
       " '127.Luu-Diec_P': 126,\n",
       " '128.Ly_Nha_K': 127,\n",
       " '129.Mai_H': 128,\n",
       " '130.Mai_Ng': 129,\n",
       " '131.Mau_Thanh_Th': 130,\n",
       " '132.Mid_Ng': 131,\n",
       " '133.Minh_H': 132,\n",
       " '134.Minh_Tr': 133,\n",
       " '135.Minh_T': 134,\n",
       " '136.Miu_L': 135,\n",
       " '137.My_T': 136,\n",
       " '138.Ngo_Thanh_V': 137,\n",
       " '139.Ngoc_Qu': 138,\n",
       " '140.Nguyen_Thi_Tram': 139,\n",
       " '141.Pham_H': 140,\n",
       " '142.Pham_My_L': 141,\n",
       " '143.Pham_Thanh_H': 142,\n",
       " '144.Quynh_Anh_Sh': 143,\n",
       " '145.Suzy': 144,\n",
       " '146.Tam_T': 145,\n",
       " '147.Thu_M': 146,\n",
       " '148.Thu_Tr': 147,\n",
       " '149.Thuy_H': 148,\n",
       " '150.Toc_T': 149,\n",
       " '151.Tran_Kieu_A': 150,\n",
       " '152.Trang_K': 151,\n",
       " '153.Trang_Ph': 152,\n",
       " '154.Trieu_Le_D': 153,\n",
       " '155.Truong_Quynh_A': 154,\n",
       " '156.Tu_H': 155,\n",
       " '157.Uyen_L': 156,\n",
       " '158.Van_h': 157,\n",
       " '159.Van_Mai_H': 158,\n",
       " '160.Viet_H': 159,\n",
       " '161.Vo_Hoang_Y': 160,\n",
       " '162.Vu_Cat_T': 161,\n",
       " '163.Xa_Thi_M': 162,\n",
       " '164.Yen_Nhi_H': 163}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28412"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(images.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "images = images[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, temp_images, train_labels, temp_labels = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(temp_images, temp_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen1 = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 2, 2, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 164)               42148     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,937,252\n",
      "Trainable params: 1,222,564\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen2 = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator1 = train_datagen1.flow(train_images, train_labels, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(val_images, val_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "533/533 [==============================] - 23s 31ms/step - loss: 4.9703 - accuracy: 0.0201 - val_loss: 4.7068 - val_accuracy: 0.0345\n",
      "Epoch 2/100\n",
      "533/533 [==============================] - 16s 30ms/step - loss: 4.6381 - accuracy: 0.0456 - val_loss: 4.4180 - val_accuracy: 0.0651\n",
      "Epoch 3/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 4.4766 - accuracy: 0.0639 - val_loss: 4.2877 - val_accuracy: 0.0913\n",
      "Epoch 4/100\n",
      "533/533 [==============================] - 15s 29ms/step - loss: 4.3817 - accuracy: 0.0736 - val_loss: 4.1938 - val_accuracy: 0.0959\n",
      "Epoch 5/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 4.3007 - accuracy: 0.0841 - val_loss: 4.1193 - val_accuracy: 0.1133\n",
      "Epoch 6/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 4.2313 - accuracy: 0.0939 - val_loss: 4.0858 - val_accuracy: 0.1170\n",
      "Epoch 7/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 4.1886 - accuracy: 0.1010 - val_loss: 4.0337 - val_accuracy: 0.1221\n",
      "Epoch 8/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 4.1315 - accuracy: 0.1086 - val_loss: 4.0052 - val_accuracy: 0.1262\n",
      "Epoch 9/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 4.0854 - accuracy: 0.1085 - val_loss: 3.9429 - val_accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 4.0615 - accuracy: 0.1161 - val_loss: 3.9486 - val_accuracy: 0.1376\n",
      "Epoch 11/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 4.0101 - accuracy: 0.1249 - val_loss: 3.9390 - val_accuracy: 0.1450\n",
      "Epoch 12/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.9717 - accuracy: 0.1285 - val_loss: 3.8858 - val_accuracy: 0.1551\n",
      "Epoch 13/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.9567 - accuracy: 0.1306 - val_loss: 3.9210 - val_accuracy: 0.1466\n",
      "Epoch 14/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.9263 - accuracy: 0.1357 - val_loss: 3.8489 - val_accuracy: 0.1515\n",
      "Epoch 15/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.9070 - accuracy: 0.1362 - val_loss: 3.8572 - val_accuracy: 0.1591\n",
      "Epoch 16/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.8680 - accuracy: 0.1430 - val_loss: 3.8255 - val_accuracy: 0.1584\n",
      "Epoch 17/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.8550 - accuracy: 0.1444 - val_loss: 3.8085 - val_accuracy: 0.1626\n",
      "Epoch 18/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.8246 - accuracy: 0.1532 - val_loss: 3.8310 - val_accuracy: 0.1640\n",
      "Epoch 19/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.8100 - accuracy: 0.1525 - val_loss: 3.8138 - val_accuracy: 0.1556\n",
      "Epoch 20/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.8037 - accuracy: 0.1575 - val_loss: 3.8679 - val_accuracy: 0.1551\n",
      "Epoch 21/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.7845 - accuracy: 0.1606 - val_loss: 3.8371 - val_accuracy: 0.1619\n",
      "Epoch 22/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.7545 - accuracy: 0.1608 - val_loss: 3.8217 - val_accuracy: 0.1711\n",
      "Epoch 23/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.7422 - accuracy: 0.1633 - val_loss: 3.8059 - val_accuracy: 0.1651\n",
      "Epoch 24/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.7580 - accuracy: 0.1597 - val_loss: 3.7916 - val_accuracy: 0.1721\n",
      "Epoch 25/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.7202 - accuracy: 0.1666 - val_loss: 3.7814 - val_accuracy: 0.1730\n",
      "Epoch 26/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.7054 - accuracy: 0.1661 - val_loss: 3.8051 - val_accuracy: 0.1762\n",
      "Epoch 27/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.6844 - accuracy: 0.1741 - val_loss: 3.8020 - val_accuracy: 0.1660\n",
      "Epoch 28/100\n",
      "533/533 [==============================] - 15s 29ms/step - loss: 3.6887 - accuracy: 0.1732 - val_loss: 3.7702 - val_accuracy: 0.1755\n",
      "Epoch 29/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.6909 - accuracy: 0.1674 - val_loss: 3.7878 - val_accuracy: 0.1739\n",
      "Epoch 30/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.6586 - accuracy: 0.1771 - val_loss: 3.8025 - val_accuracy: 0.1755\n",
      "Epoch 31/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.6278 - accuracy: 0.1811 - val_loss: 3.7295 - val_accuracy: 0.1843\n",
      "Epoch 32/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.6491 - accuracy: 0.1805 - val_loss: 3.7452 - val_accuracy: 0.1786\n",
      "Epoch 33/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.6489 - accuracy: 0.1766 - val_loss: 3.7429 - val_accuracy: 0.1869\n",
      "Epoch 34/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.6110 - accuracy: 0.1845 - val_loss: 3.7727 - val_accuracy: 0.1837\n",
      "Epoch 35/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.6067 - accuracy: 0.1861 - val_loss: 3.7999 - val_accuracy: 0.1809\n",
      "Epoch 36/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.5998 - accuracy: 0.1829 - val_loss: 3.7763 - val_accuracy: 0.1815\n",
      "Epoch 37/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.5854 - accuracy: 0.1878 - val_loss: 3.7678 - val_accuracy: 0.1822\n",
      "Epoch 38/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.5806 - accuracy: 0.1897 - val_loss: 3.7564 - val_accuracy: 0.1830\n",
      "Epoch 39/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.5665 - accuracy: 0.1860 - val_loss: 3.7767 - val_accuracy: 0.1853\n",
      "Epoch 40/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.5548 - accuracy: 0.1926 - val_loss: 3.7531 - val_accuracy: 0.1853\n",
      "Epoch 41/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5499 - accuracy: 0.1936 - val_loss: 3.7609 - val_accuracy: 0.1841\n",
      "Epoch 42/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5549 - accuracy: 0.1887 - val_loss: 3.7768 - val_accuracy: 0.1811\n",
      "Epoch 43/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.5377 - accuracy: 0.1977 - val_loss: 3.7983 - val_accuracy: 0.1844\n",
      "Epoch 44/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.5375 - accuracy: 0.1913 - val_loss: 3.7838 - val_accuracy: 0.1846\n",
      "Epoch 45/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5164 - accuracy: 0.1974 - val_loss: 3.7983 - val_accuracy: 0.1881\n",
      "Epoch 46/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.5184 - accuracy: 0.1987 - val_loss: 3.8058 - val_accuracy: 0.1836\n",
      "Epoch 47/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.5221 - accuracy: 0.1962 - val_loss: 3.7777 - val_accuracy: 0.1859\n",
      "Epoch 48/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.5158 - accuracy: 0.1983 - val_loss: 3.7845 - val_accuracy: 0.1880\n",
      "Epoch 49/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5135 - accuracy: 0.2030 - val_loss: 3.7320 - val_accuracy: 0.1894\n",
      "Epoch 50/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4850 - accuracy: 0.2086 - val_loss: 3.8007 - val_accuracy: 0.1938\n",
      "Epoch 51/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4945 - accuracy: 0.2051 - val_loss: 3.7595 - val_accuracy: 0.1957\n",
      "Epoch 52/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.4693 - accuracy: 0.2073 - val_loss: 3.7829 - val_accuracy: 0.1860\n",
      "Epoch 53/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4749 - accuracy: 0.2013 - val_loss: 3.7570 - val_accuracy: 0.1911\n",
      "Epoch 54/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4858 - accuracy: 0.2044 - val_loss: 3.7659 - val_accuracy: 0.1941\n",
      "Epoch 55/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4725 - accuracy: 0.2040 - val_loss: 3.7680 - val_accuracy: 0.1887\n",
      "Epoch 56/100\n",
      "533/533 [==============================] - 15s 29ms/step - loss: 3.4583 - accuracy: 0.2051 - val_loss: 3.7726 - val_accuracy: 0.1890\n",
      "Epoch 57/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.4598 - accuracy: 0.2100 - val_loss: 3.7982 - val_accuracy: 0.1920\n",
      "Epoch 58/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4404 - accuracy: 0.2066 - val_loss: 3.7857 - val_accuracy: 0.1932\n",
      "Epoch 59/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.4536 - accuracy: 0.2083 - val_loss: 3.7859 - val_accuracy: 0.1924\n",
      "Epoch 60/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4260 - accuracy: 0.2134 - val_loss: 3.7692 - val_accuracy: 0.1927\n",
      "Epoch 61/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4331 - accuracy: 0.2128 - val_loss: 3.7856 - val_accuracy: 0.1869\n",
      "Epoch 62/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4229 - accuracy: 0.2122 - val_loss: 3.8094 - val_accuracy: 0.1950\n",
      "Epoch 63/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4182 - accuracy: 0.2142 - val_loss: 3.8400 - val_accuracy: 0.1883\n",
      "Epoch 64/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4342 - accuracy: 0.2085 - val_loss: 3.7982 - val_accuracy: 0.1915\n",
      "Epoch 65/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4268 - accuracy: 0.2125 - val_loss: 3.7691 - val_accuracy: 0.1989\n",
      "Epoch 66/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4229 - accuracy: 0.2168 - val_loss: 3.7912 - val_accuracy: 0.1918\n",
      "Epoch 67/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4158 - accuracy: 0.2149 - val_loss: 3.8000 - val_accuracy: 0.1948\n",
      "Epoch 68/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4033 - accuracy: 0.2173 - val_loss: 3.8222 - val_accuracy: 0.1910\n",
      "Epoch 69/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3920 - accuracy: 0.2170 - val_loss: 3.7882 - val_accuracy: 0.1966\n",
      "Epoch 70/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4192 - accuracy: 0.2193 - val_loss: 3.8530 - val_accuracy: 0.1890\n",
      "Epoch 71/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3852 - accuracy: 0.2180 - val_loss: 3.8288 - val_accuracy: 0.1920\n",
      "Epoch 72/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3910 - accuracy: 0.2198 - val_loss: 3.7781 - val_accuracy: 0.1973\n",
      "Epoch 73/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.3997 - accuracy: 0.2176 - val_loss: 3.8052 - val_accuracy: 0.1859\n",
      "Epoch 74/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3877 - accuracy: 0.2165 - val_loss: 3.8298 - val_accuracy: 0.1888\n",
      "Epoch 75/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.3789 - accuracy: 0.2226 - val_loss: 3.7817 - val_accuracy: 0.1971\n",
      "Epoch 76/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.3715 - accuracy: 0.2203 - val_loss: 3.8235 - val_accuracy: 0.1946\n",
      "Epoch 77/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.3696 - accuracy: 0.2216 - val_loss: 3.7657 - val_accuracy: 0.1946\n",
      "Epoch 78/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.3728 - accuracy: 0.2217 - val_loss: 3.7992 - val_accuracy: 0.1924\n",
      "Epoch 79/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.3554 - accuracy: 0.2203 - val_loss: 3.8832 - val_accuracy: 0.1844\n",
      "Epoch 80/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.3673 - accuracy: 0.2197 - val_loss: 3.8229 - val_accuracy: 0.1941\n",
      "Epoch 81/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3628 - accuracy: 0.2234 - val_loss: 3.8181 - val_accuracy: 0.1895\n",
      "Epoch 82/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.3412 - accuracy: 0.2243 - val_loss: 3.7756 - val_accuracy: 0.2008\n",
      "Epoch 83/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.3351 - accuracy: 0.2289 - val_loss: 3.8286 - val_accuracy: 0.1955\n",
      "Epoch 84/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3401 - accuracy: 0.2280 - val_loss: 3.8083 - val_accuracy: 0.1943\n",
      "Epoch 85/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.3519 - accuracy: 0.2247 - val_loss: 3.7898 - val_accuracy: 0.1996\n",
      "Epoch 86/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3626 - accuracy: 0.2267 - val_loss: 3.8225 - val_accuracy: 0.1957\n",
      "Epoch 87/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3240 - accuracy: 0.2274 - val_loss: 3.8183 - val_accuracy: 0.1966\n",
      "Epoch 88/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3389 - accuracy: 0.2252 - val_loss: 3.7991 - val_accuracy: 0.1929\n",
      "Epoch 89/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3355 - accuracy: 0.2265 - val_loss: 3.8140 - val_accuracy: 0.2010\n",
      "Epoch 90/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3233 - accuracy: 0.2340 - val_loss: 3.8195 - val_accuracy: 0.1966\n",
      "Epoch 91/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3393 - accuracy: 0.2240 - val_loss: 3.8401 - val_accuracy: 0.1962\n",
      "Epoch 92/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3271 - accuracy: 0.2262 - val_loss: 3.8129 - val_accuracy: 0.1954\n",
      "Epoch 93/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3274 - accuracy: 0.2253 - val_loss: 3.9136 - val_accuracy: 0.1874\n",
      "Epoch 94/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3400 - accuracy: 0.2297 - val_loss: 3.8605 - val_accuracy: 0.1931\n",
      "Epoch 95/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3329 - accuracy: 0.2294 - val_loss: 3.8901 - val_accuracy: 0.1931\n",
      "Epoch 96/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3146 - accuracy: 0.2314 - val_loss: 3.8744 - val_accuracy: 0.2015\n",
      "Epoch 97/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3131 - accuracy: 0.2342 - val_loss: 3.8271 - val_accuracy: 0.1959\n",
      "Epoch 98/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3272 - accuracy: 0.2292 - val_loss: 3.8314 - val_accuracy: 0.1945\n",
      "Epoch 99/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.3102 - accuracy: 0.2337 - val_loss: 3.8472 - val_accuracy: 0.1994\n",
      "Epoch 100/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.2904 - accuracy: 0.2317 - val_loss: 3.8252 - val_accuracy: 0.2064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd541e8940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator1, epochs=epochs, validation_data= val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator2 = train_datagen2.flow(train_images, train_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5918 - accuracy: 0.1933 - val_loss: 3.8810 - val_accuracy: 0.1844\n",
      "Epoch 2/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.5547 - accuracy: 0.1935 - val_loss: 3.8666 - val_accuracy: 0.1920\n",
      "Epoch 3/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.5673 - accuracy: 0.1991 - val_loss: 3.8170 - val_accuracy: 0.1899\n",
      "Epoch 4/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5630 - accuracy: 0.1937 - val_loss: 3.8413 - val_accuracy: 0.1924\n",
      "Epoch 5/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.5730 - accuracy: 0.1907 - val_loss: 3.8382 - val_accuracy: 0.1920\n",
      "Epoch 6/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5520 - accuracy: 0.1968 - val_loss: 3.8789 - val_accuracy: 0.1906\n",
      "Epoch 7/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5602 - accuracy: 0.1909 - val_loss: 3.8321 - val_accuracy: 0.1910\n",
      "Epoch 8/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5563 - accuracy: 0.1959 - val_loss: 3.8722 - val_accuracy: 0.1827\n",
      "Epoch 9/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5579 - accuracy: 0.1927 - val_loss: 3.8243 - val_accuracy: 0.1924\n",
      "Epoch 10/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5451 - accuracy: 0.1969 - val_loss: 3.8558 - val_accuracy: 0.1901\n",
      "Epoch 11/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5438 - accuracy: 0.1948 - val_loss: 3.8795 - val_accuracy: 0.1848\n",
      "Epoch 12/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5264 - accuracy: 0.1968 - val_loss: 3.8820 - val_accuracy: 0.1887\n",
      "Epoch 13/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5494 - accuracy: 0.1938 - val_loss: 3.9047 - val_accuracy: 0.1800\n",
      "Epoch 14/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5428 - accuracy: 0.1995 - val_loss: 3.8822 - val_accuracy: 0.1904\n",
      "Epoch 15/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5623 - accuracy: 0.1933 - val_loss: 3.8963 - val_accuracy: 0.1853\n",
      "Epoch 16/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.5266 - accuracy: 0.1958 - val_loss: 3.9017 - val_accuracy: 0.1888\n",
      "Epoch 17/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5424 - accuracy: 0.1982 - val_loss: 3.8817 - val_accuracy: 0.1894\n",
      "Epoch 18/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5286 - accuracy: 0.2009 - val_loss: 3.8522 - val_accuracy: 0.1862\n",
      "Epoch 19/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.5384 - accuracy: 0.2007 - val_loss: 3.8326 - val_accuracy: 0.1895\n",
      "Epoch 20/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5085 - accuracy: 0.2022 - val_loss: 3.8423 - val_accuracy: 0.1918\n",
      "Epoch 21/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5495 - accuracy: 0.1935 - val_loss: 3.8310 - val_accuracy: 0.1927\n",
      "Epoch 22/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5067 - accuracy: 0.1996 - val_loss: 3.8216 - val_accuracy: 0.1934\n",
      "Epoch 23/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5174 - accuracy: 0.2031 - val_loss: 3.8443 - val_accuracy: 0.1922\n",
      "Epoch 24/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5183 - accuracy: 0.2023 - val_loss: 3.8525 - val_accuracy: 0.1873\n",
      "Epoch 25/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5401 - accuracy: 0.1994 - val_loss: 3.9321 - val_accuracy: 0.1871\n",
      "Epoch 26/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5059 - accuracy: 0.2007 - val_loss: 3.9012 - val_accuracy: 0.1825\n",
      "Epoch 27/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5015 - accuracy: 0.2029 - val_loss: 3.8915 - val_accuracy: 0.1920\n",
      "Epoch 28/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5165 - accuracy: 0.1975 - val_loss: 3.8934 - val_accuracy: 0.1857\n",
      "Epoch 29/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5257 - accuracy: 0.2037 - val_loss: 3.8410 - val_accuracy: 0.1851\n",
      "Epoch 30/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5147 - accuracy: 0.1980 - val_loss: 3.8780 - val_accuracy: 0.1855\n",
      "Epoch 31/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5308 - accuracy: 0.2020 - val_loss: 3.8297 - val_accuracy: 0.1920\n",
      "Epoch 32/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4971 - accuracy: 0.2014 - val_loss: 3.9381 - val_accuracy: 0.1811\n",
      "Epoch 33/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4899 - accuracy: 0.2044 - val_loss: 3.8860 - val_accuracy: 0.1841\n",
      "Epoch 34/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5289 - accuracy: 0.2003 - val_loss: 3.8478 - val_accuracy: 0.1902\n",
      "Epoch 35/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4899 - accuracy: 0.2050 - val_loss: 3.8544 - val_accuracy: 0.1975\n",
      "Epoch 36/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5074 - accuracy: 0.2019 - val_loss: 3.8792 - val_accuracy: 0.1855\n",
      "Epoch 37/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5126 - accuracy: 0.2037 - val_loss: 3.8727 - val_accuracy: 0.1860\n",
      "Epoch 38/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5155 - accuracy: 0.2031 - val_loss: 3.8314 - val_accuracy: 0.1924\n",
      "Epoch 39/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5012 - accuracy: 0.2054 - val_loss: 3.9250 - val_accuracy: 0.1880\n",
      "Epoch 40/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5000 - accuracy: 0.2045 - val_loss: 3.8737 - val_accuracy: 0.1883\n",
      "Epoch 41/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4997 - accuracy: 0.2048 - val_loss: 3.8435 - val_accuracy: 0.1908\n",
      "Epoch 42/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5169 - accuracy: 0.2050 - val_loss: 3.8291 - val_accuracy: 0.1906\n",
      "Epoch 43/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4892 - accuracy: 0.2044 - val_loss: 3.9037 - val_accuracy: 0.1832\n",
      "Epoch 44/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4901 - accuracy: 0.2009 - val_loss: 3.9172 - val_accuracy: 0.1902\n",
      "Epoch 45/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4970 - accuracy: 0.2016 - val_loss: 3.8310 - val_accuracy: 0.1975\n",
      "Epoch 46/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4916 - accuracy: 0.2071 - val_loss: 3.8542 - val_accuracy: 0.1954\n",
      "Epoch 47/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4897 - accuracy: 0.2043 - val_loss: 3.8270 - val_accuracy: 0.1915\n",
      "Epoch 48/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4799 - accuracy: 0.2068 - val_loss: 3.8353 - val_accuracy: 0.1918\n",
      "Epoch 49/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.4988 - accuracy: 0.2067 - val_loss: 3.8192 - val_accuracy: 0.1938\n",
      "Epoch 50/100\n",
      "533/533 [==============================] - 15s 29ms/step - loss: 3.4762 - accuracy: 0.2074 - val_loss: 3.8485 - val_accuracy: 0.1922\n",
      "Epoch 51/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.4876 - accuracy: 0.2071 - val_loss: 3.9185 - val_accuracy: 0.1867\n",
      "Epoch 52/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.4718 - accuracy: 0.2060 - val_loss: 3.8809 - val_accuracy: 0.1920\n",
      "Epoch 53/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.4827 - accuracy: 0.2060 - val_loss: 3.9062 - val_accuracy: 0.1934\n",
      "Epoch 54/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4730 - accuracy: 0.2124 - val_loss: 3.8369 - val_accuracy: 0.1971\n",
      "Epoch 55/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4996 - accuracy: 0.2066 - val_loss: 3.8689 - val_accuracy: 0.1964\n",
      "Epoch 56/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4983 - accuracy: 0.2026 - val_loss: 3.8750 - val_accuracy: 0.1983\n",
      "Epoch 57/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.5027 - accuracy: 0.2021 - val_loss: 3.9004 - val_accuracy: 0.1895\n",
      "Epoch 58/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4892 - accuracy: 0.2073 - val_loss: 3.8334 - val_accuracy: 0.1934\n",
      "Epoch 59/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4888 - accuracy: 0.2084 - val_loss: 3.9094 - val_accuracy: 0.1957\n",
      "Epoch 60/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4863 - accuracy: 0.2102 - val_loss: 3.9225 - val_accuracy: 0.1931\n",
      "Epoch 61/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4792 - accuracy: 0.2094 - val_loss: 3.9425 - val_accuracy: 0.1832\n",
      "Epoch 62/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4892 - accuracy: 0.2035 - val_loss: 3.8703 - val_accuracy: 0.1969\n",
      "Epoch 63/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4635 - accuracy: 0.2096 - val_loss: 3.8852 - val_accuracy: 0.1850\n",
      "Epoch 64/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4842 - accuracy: 0.2057 - val_loss: 3.8425 - val_accuracy: 0.1982\n",
      "Epoch 65/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4813 - accuracy: 0.2109 - val_loss: 3.8576 - val_accuracy: 0.1999\n",
      "Epoch 66/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4825 - accuracy: 0.2055 - val_loss: 3.9598 - val_accuracy: 0.1932\n",
      "Epoch 67/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4718 - accuracy: 0.2084 - val_loss: 3.9599 - val_accuracy: 0.1894\n",
      "Epoch 68/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4698 - accuracy: 0.2117 - val_loss: 3.9123 - val_accuracy: 0.1911\n",
      "Epoch 69/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4851 - accuracy: 0.2090 - val_loss: 3.8949 - val_accuracy: 0.1938\n",
      "Epoch 70/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4632 - accuracy: 0.2175 - val_loss: 3.9016 - val_accuracy: 0.1915\n",
      "Epoch 71/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4697 - accuracy: 0.2095 - val_loss: 3.8577 - val_accuracy: 0.1980\n",
      "Epoch 72/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.4805 - accuracy: 0.2090 - val_loss: 3.8745 - val_accuracy: 0.1917\n",
      "Epoch 73/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.4441 - accuracy: 0.2134 - val_loss: 3.9308 - val_accuracy: 0.1885\n",
      "Epoch 74/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4784 - accuracy: 0.2026 - val_loss: 3.9662 - val_accuracy: 0.1836\n",
      "Epoch 75/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.4427 - accuracy: 0.2134 - val_loss: 3.8931 - val_accuracy: 0.1954\n",
      "Epoch 76/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4510 - accuracy: 0.2100 - val_loss: 3.8923 - val_accuracy: 0.1962\n",
      "Epoch 77/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4831 - accuracy: 0.2091 - val_loss: 3.9112 - val_accuracy: 0.1892\n",
      "Epoch 78/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4630 - accuracy: 0.2106 - val_loss: 3.9172 - val_accuracy: 0.1887\n",
      "Epoch 79/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4598 - accuracy: 0.2088 - val_loss: 3.9042 - val_accuracy: 0.1927\n",
      "Epoch 80/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4767 - accuracy: 0.2082 - val_loss: 3.9682 - val_accuracy: 0.1844\n",
      "Epoch 81/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4645 - accuracy: 0.2136 - val_loss: 3.8868 - val_accuracy: 0.1888\n",
      "Epoch 82/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4697 - accuracy: 0.2102 - val_loss: 3.8714 - val_accuracy: 0.1957\n",
      "Epoch 83/100\n",
      "533/533 [==============================] - 14s 25ms/step - loss: 3.4586 - accuracy: 0.2114 - val_loss: 3.8879 - val_accuracy: 0.1908\n",
      "Epoch 84/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4524 - accuracy: 0.2108 - val_loss: 3.9006 - val_accuracy: 0.1881\n",
      "Epoch 85/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4474 - accuracy: 0.2115 - val_loss: 3.8450 - val_accuracy: 0.1925\n",
      "Epoch 86/100\n",
      "533/533 [==============================] - 14s 25ms/step - loss: 3.4681 - accuracy: 0.2098 - val_loss: 3.8665 - val_accuracy: 0.1901\n",
      "Epoch 87/100\n",
      "533/533 [==============================] - 14s 25ms/step - loss: 3.4584 - accuracy: 0.2118 - val_loss: 3.9050 - val_accuracy: 0.1902\n",
      "Epoch 88/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4552 - accuracy: 0.2098 - val_loss: 3.8896 - val_accuracy: 0.1954\n",
      "Epoch 89/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4514 - accuracy: 0.2104 - val_loss: 3.8730 - val_accuracy: 0.1990\n",
      "Epoch 90/100\n",
      "533/533 [==============================] - 14s 26ms/step - loss: 3.4469 - accuracy: 0.2156 - val_loss: 3.9012 - val_accuracy: 0.1992\n",
      "Epoch 91/100\n",
      "533/533 [==============================] - 15s 28ms/step - loss: 3.4664 - accuracy: 0.2111 - val_loss: 3.9078 - val_accuracy: 0.1931\n",
      "Epoch 92/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4290 - accuracy: 0.2153 - val_loss: 3.9083 - val_accuracy: 0.1915\n",
      "Epoch 93/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4402 - accuracy: 0.2115 - val_loss: 3.9164 - val_accuracy: 0.1941\n",
      "Epoch 94/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4592 - accuracy: 0.2117 - val_loss: 3.8214 - val_accuracy: 0.2059\n",
      "Epoch 95/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4618 - accuracy: 0.2090 - val_loss: 3.9493 - val_accuracy: 0.1978\n",
      "Epoch 96/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4574 - accuracy: 0.2121 - val_loss: 3.9261 - val_accuracy: 0.1892\n",
      "Epoch 97/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4454 - accuracy: 0.2157 - val_loss: 3.8726 - val_accuracy: 0.1934\n",
      "Epoch 98/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4499 - accuracy: 0.2131 - val_loss: 3.8904 - val_accuracy: 0.1968\n",
      "Epoch 99/100\n",
      "533/533 [==============================] - 14s 27ms/step - loss: 3.4287 - accuracy: 0.2121 - val_loss: 3.8742 - val_accuracy: 0.1906\n",
      "Epoch 100/100\n",
      "533/533 [==============================] - 15s 27ms/step - loss: 3.4439 - accuracy: 0.2106 - val_loss: 3.9493 - val_accuracy: 0.1902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd268eae60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator2, epochs=epochs, validation_data=val_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
